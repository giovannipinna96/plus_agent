#!/usr/bin/env python3
"""
Test script for validating TODO 3 and TODO 6 implementations in smolagents_multiagent_system.py

Tests:
1. TODO 3: Planner-Executor-Answerer architecture
2. TODO 6: Lazy loading and GPU memory management
3. Integration: Full workflow test

Usage:
    uv run python plus_agent/test_smolagents_todos.py
"""

import sys
import os
import torch
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent))

print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë              TODO 3 + TODO 6 VALIDATION TESTS                   ‚ïë
‚ïë         Testing Planner-Executor-Answerer + Lazy Loading       ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
""")


def test_todo3_agent_creation():
    """Test TODO 3: Verify Planner, Executor, and Answerer agents can be created."""
    print("\n" + "="*60)
    print("TEST 1: TODO 3 - Agent Creation")
    print("="*60)

    from smolagents_multiagent_system import create_planner_agent, create_executor_agent, create_answerer_agent

    try:
        # Test PlannerAgent creation
        print("\n1Ô∏è‚É£ Testing PlannerAgent creation...")
        model_p, planner = create_planner_agent()
        assert planner is not None, "Planner agent should not be None"
        assert planner.name == "PlannerAgent", f"Expected name 'PlannerAgent', got '{planner.name}'"
        assert len(planner.tools) == 0, f"Planner should have 0 tools, got {len(planner.tools)}"
        print("‚úÖ PlannerAgent created successfully (0 tools, reasoning only)")
        del model_p, planner

        # Test ExecutorAgent creation
        print("\n2Ô∏è‚É£ Testing ExecutorAgent creation...")
        model_e, executor = create_executor_agent()
        assert executor is not None, "Executor agent should not be None"
        assert executor.name == "ExecutorAgent", f"Expected name 'ExecutorAgent', got '{executor.name}'"
        num_tools = len(executor.tools)
        assert num_tools > 40, f"Executor should have 40+ tools, got {num_tools}"
        print(f"‚úÖ ExecutorAgent created successfully ({num_tools} tools)")
        del model_e, executor

        # Test AnswererAgent creation
        print("\n3Ô∏è‚É£ Testing AnswererAgent creation...")
        model_a, answerer = create_answerer_agent()
        assert answerer is not None, "Answerer agent should not be None"
        assert answerer.name == "AnswererAgent", f"Expected name 'AnswererAgent', got '{answerer.name}'"
        assert len(answerer.tools) == 0, f"Answerer should have 0 tools, got {len(answerer.tools)}"
        print("‚úÖ AnswererAgent created successfully (0 tools, synthesis only)")
        del model_a, answerer

        print("\n‚úÖ TEST 1 PASSED: All three agents (Planner, Executor, Answerer) created successfully!")
        return True

    except Exception as e:
        print(f"\n‚ùå TEST 1 FAILED: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_todo6_lazy_loading():
    """Test TODO 6: Verify lazy loading and memory management."""
    print("\n" + "="*60)
    print("TEST 2: TODO 6 - Lazy Loading & GPU Memory Management")
    print("="*60)

    from smolagents_multiagent_system import load_agent_lazy, unload_agent

    try:
        # Get initial GPU memory (if available)
        if torch.cuda.is_available():
            torch.cuda.synchronize()
            initial_mem = torch.cuda.memory_allocated() / 1e9
            print(f"\nüìä Initial GPU memory: {initial_mem:.2f} GB")
        else:
            initial_mem = 0
            print("\n‚ö†Ô∏è  No GPU available, skipping GPU memory tests")

        # Test lazy loading Planner
        print("\n1Ô∏è‚É£ Testing lazy loading of Planner...")
        model, agent = load_agent_lazy("planner")
        assert model is not None, "Model should not be None"
        assert agent is not None, "Agent should not be None"

        if torch.cuda.is_available():
            torch.cuda.synchronize()
            after_load = torch.cuda.memory_allocated() / 1e9
            print(f"üìä Memory after Planner load: {after_load:.2f} GB")

        # Test unloading
        print("\n2Ô∏è‚É£ Testing unloading of Planner...")
        unload_agent(model, agent, "planner")

        if torch.cuda.is_available():
            torch.cuda.synchronize()
            after_unload = torch.cuda.memory_allocated() / 1e9
            print(f"üìä Memory after Planner unload: {after_unload:.2f} GB")

            # Verify memory was freed
            memory_freed = after_load - after_unload
            print(f"üìä Memory freed: {memory_freed:.2f} GB")
            assert memory_freed > 0, f"Memory should be freed after unload, but got {memory_freed:.2f} GB"

        print("\n‚úÖ TEST 2 PASSED: Lazy loading and unloading work correctly!")
        return True

    except Exception as e:
        print(f"\n‚ùå TEST 2 FAILED: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_workflow_integration():
    """Test the complete Planner ‚Üí Executor ‚Üí Answerer workflow."""
    print("\n" + "="*60)
    print("TEST 3: Integration - Full Workflow Test")
    print("="*60)

    from smolagents_multiagent_system import run_analysis

    try:
        # Simple test question
        test_prompt = "How many passengers were in the dataset?"
        test_file = "data/titanic.csv"

        print(f"\nüìù Test prompt: {test_prompt}")
        print(f"üìÅ Test file: {test_file}")

        # Check if file exists
        if not os.path.exists(test_file):
            print(f"‚ö†Ô∏è  Skipping workflow test: {test_file} not found")
            print("   To run this test, ensure the Titanic dataset is available")
            return True  # Don't fail if dataset not found

        print("\nüöÄ Running complete Planner ‚Üí Executor ‚Üí Answerer workflow...")

        # Run analysis (this will test lazy loading automatically)
        result = run_analysis(test_prompt, test_file)

        assert result is not None, "Result should not be None"
        assert len(result) > 0, "Result should not be empty"
        print(f"\nüìã Final answer received (length: {len(result)} characters)")

        # Check if result mentions "891" (number of passengers in Titanic dataset)
        if "891" in result or "eight hundred" in result.lower():
            print("‚úÖ Result contains expected information about passenger count!")
        else:
            print("‚ö†Ô∏è  Result may not contain expected information, but workflow completed")

        print("\n‚úÖ TEST 3 PASSED: Complete workflow executed successfully!")
        return True

    except Exception as e:
        print(f"\n‚ùå TEST 3 FAILED: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_dataframe_state_management():
    """Test TODO 2: Verify in-memory DataFrame management."""
    print("\n" + "="*60)
    print("TEST 4: TODO 2 - In-Memory DataFrame State Management")
    print("="*60)

    from smolagents_tools import df_state_manager

    try:
        test_file = "data/titanic.csv"

        if not os.path.exists(test_file):
            print(f"‚ö†Ô∏è  Skipping DataFrame test: {test_file} not found")
            return True

        print(f"\n1Ô∏è‚É£ Loading dataset into memory: {test_file}")
        df = df_state_manager.load_dataframe(test_file)
        assert df is not None, "DataFrame should not be None"
        print(f"‚úÖ Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns")

        print("\n2Ô∏è‚É£ Getting current DataFrame from memory...")
        df_current = df_state_manager.get_current_dataframe()
        assert df_current is not None, "Current DataFrame should not be None"
        assert df_current.shape == df.shape, "Shapes should match"
        print(f"‚úÖ Current DataFrame retrieved: {df_current.shape}")

        print("\n3Ô∏è‚É£ Checking metadata...")
        metadata = df_state_manager.get_metadata()
        assert metadata is not None, "Metadata should not be None"
        print(f"‚úÖ Metadata available: {list(metadata.keys())}")

        print("\n‚úÖ TEST 4 PASSED: In-memory DataFrame management works correctly!")
        return True

    except Exception as e:
        print(f"\n‚ùå TEST 4 FAILED: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Run all tests and report results."""
    print("\nüöÄ Starting TODO validation tests...")

    results = {
        "TODO 3 - Agent Creation": test_todo3_agent_creation(),
        "TODO 6 - Lazy Loading": test_todo6_lazy_loading(),
        "TODO 2 - DataFrame State": test_dataframe_state_management(),
        "Integration - Full Workflow": test_workflow_integration(),
    }

    # Summary
    print("\n" + "="*60)
    print("TEST SUMMARY")
    print("="*60)

    passed = sum(results.values())
    total = len(results)

    for test_name, result in results.items():
        status = "‚úÖ PASSED" if result else "‚ùå FAILED"
        print(f"{status}: {test_name}")

    print(f"\n{'='*60}")
    print(f"TOTAL: {passed}/{total} tests passed")
    print(f"{'='*60}")

    if passed == total:
        print("\nüéâ ALL TESTS PASSED! TODO 3 and TODO 6 implementations are working correctly!")
        return 0
    else:
        print(f"\n‚ö†Ô∏è  {total - passed} test(s) failed. Please review the errors above.")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
